#!/bin/bash
#
# oi - One-command LLM chat interface for llama.cpp
# Interactive model selection and chat launcher
#

set -e

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
LIB_DIR="${SCRIPT_DIR}/lib"
LLAMA_CPP_DIR="${HOME}/llama.cpp"
MODELS_DIR="${LLAMA_CPP_DIR}/models"
LLAMA_CLI="${LLAMA_CPP_DIR}/build/bin/llama-cli"
DEFAULT_QUANT="Q4_K_M"
DEFAULT_CONTEXT=4096

# Colors for output using ANSI escape sequences
RED=$'\033[0;31m'
GREEN=$'\033[0;32m'
YELLOW=$'\033[1;33m'
BLUE=$'\033[0;34m'
CYAN=$'\033[0;36m'
NC=$'\033[0m' # No Color

# Help message
show_help() {
    cat <<EOF
oi - One-command LLM chat interface

USAGE:
    oi [OPTIONS]

OPTIONS:
    -m, --model <id>         Directly select model by ID
    -q, --quant <quant>      Specify quantization (default: ${DEFAULT_QUANT})
    -l, --list              List available models
    -i, --installed         List installed models only
    -d, --download <path>   Download custom model from HuggingFace
                            Format: username/repo-name/filename.gguf
    -h, --hardware          Show system hardware information
    -c, --context <size>    Set context size (default: ${DEFAULT_CONTEXT})
    -t, --threads <num>     Set number of CPU threads
    --help                  Show this help message

EXAMPLES:
    oi                      # Interactive model selection
    oi -m qwen2.5-3b        # Start chat with specific model
    oi -m phi-3-mini -q Q5_K_M  # Use specific quantization
    oi -l                   # List all available models
    oi -d microsoft/Phi-3-mini-4k-instruct-gguf/Phi-3-mini-4k-instruct.Q4_K_M.gguf

QUANTIZATION OPTIONS:
    Q2_K    - Smallest, fastest, lowest quality
    Q3_K_S  - Small and fast, decent quality
    Q3_K_M  - Balanced 3-bit
    Q4_K_M  - Recommended (default)
    Q4_K_L  - High quality 4-bit
    Q5_K_M  - Near-lossless quality
    Q6_K    - Very high quality
    Q8_0    - Best quality, largest

MODEL STORAGE:
    Models are stored in: ${MODELS_DIR}
EOF
}

# Check if llama.cpp is properly set up
check_llama_cpp() {
    if [ ! -d "$LLAMA_CPP_DIR" ]; then
        echo -e "${RED}Error: llama.cpp not found at ${LLAMA_CPP_DIR}${NC}"
        echo "Please clone and build llama.cpp first:"
        echo "  git clone https://github.com/ggml-org/llama.cpp.git ~/llama.cpp"
        echo "  cd ~/llama.cpp && cmake -B build && cmake --build build"
        exit 1
    fi
    
    if [ ! -f "$LLAMA_CLI" ]; then
        echo -e "${RED}Error: llama-cli not found at ${LLAMA_CLI}${NC}"
        echo "Please build llama.cpp:"
        echo "  cd ~/llama.cpp && cmake -B build && cmake --build build"
        exit 1
    fi
    
    mkdir -p "$MODELS_DIR"
}

# Detect system hardware
detect_hardware() {
    if [ -f "${LIB_DIR}/hardware_detect.sh" ]; then
        bash "${LIB_DIR}/hardware_detect.sh"
    else
        echo '{"vram_gb": 0, "ram_gb": 8, "total_memory_gb": 8, "gpu_name": "Unknown", "cuda_available": "no", "cpu_cores": 4}'
    fi
}

# Get hardware summary for display
show_hardware() {
    local hw=$(detect_hardware)
    local vram=$(echo "$hw" | grep -o '"vram_gb": [0-9.]*' | cut -d' ' -f2)
    local ram=$(echo "$hw" | grep -o '"ram_gb": [0-9]*' | cut -d' ' -f2)
    local gpu=$(echo "$hw" | grep -o '"gpu_name": "[^"]*"' | cut -d'"' -f4)
    local cuda=$(echo "$hw" | grep -o '"cuda_available": "[^"]*"' | cut -d'"' -f4)
    local cores=$(echo "$hw" | grep -o '"cpu_cores": [0-9]*' | cut -d' ' -f2)
    
    echo -e "${CYAN}Hardware Profile${NC}"
    echo -e "${CYAN}──────────────────────────────────────────────────────────${NC}"
    printf "  ${BLUE}GPU:${NC}         %s\n" "${gpu}"
    printf "  ${BLUE}VRAM:${NC}        %.1f GB\n" "${vram}"
    printf "  ${BLUE}CUDA:${NC}        %s\n" "${cuda}"
    printf "  ${BLUE}RAM:${NC}         %s GB\n" "${ram}"
    printf "  ${BLUE}CPU Cores:${NC}   %s\n" "${cores}"
    echo -e "${CYAN}──────────────────────────────────────────────────────────${NC}"
    
    # Recommendation
    if [ "${cuda}" = "yes" ] && [ "${vram%.*}" -ge 7 ]; then
        echo -e "${GREEN}✓ You can run models up to 7B parameters comfortably${NC}"
    elif [ "${cuda}" = "yes" ] && [ "${vram%.*}" -ge 4 ]; then
        echo -e "${YELLOW}● You can run models up to 4B parameters comfortably${NC}"
    elif [ "$ram" -ge 16 ]; then
        echo -e "${YELLOW}● CPU-only mode. Models up to 7B will work but slower${NC}"
    else
        echo -e "${RED}● Small models only (2-3B parameters)${NC}"
    fi
}

# Load models catalog
load_models() {
    if [ -f "${LIB_DIR}/models.json" ]; then
        cat "${LIB_DIR}/models.json"
    else
        echo '{"models": []}'
    fi
}

# Get model info by ID
get_model_info() {
    local model_id="$1"
    local models=$(load_models)
    
    # Extract model entry from JSON - escape model_id for safety
    local escaped_id=$(echo "$model_id" | sed 's/[[\.*^$()+?{|]/\\&/g')
    echo "$models" | grep -A 10 "\"id\": \"${escaped_id}\"" | head -10
}

# Check if model file exists
is_model_installed() {
    local filename="$1"
    [ -f "${MODELS_DIR}/${filename}" ]
}

# Build filename from template and quantization
build_filename() {
    local template="$1"
    local quant="$2"
    
    # If template doesn't contain {quant}, return it as-is (model-specific filename)
    if [[ "$template" != *"{quant}"* ]]; then
        echo "$template"
        return
    fi
    
    # Convert quantization to lowercase for filename
    local quant_lower=$(echo "$quant" | tr '[:upper:]' '[:lower:]')
    echo "${template//\{quant\}/$quant_lower}"
}

# Build HuggingFace download URL
build_hf_url() {
    local repo="$1"
    local filename="$2"
    echo "https://huggingface.co/${repo}/resolve/main/${filename}"
}

# Download model using curl
download_model() {
    local model_id="$1"
    local quant="$2"
    
    local model_info=$(get_model_info "$model_id")
    if [ -z "$model_info" ]; then
        echo -e "${RED}Error: Unknown model ID: ${model_id}${NC}"
        return 1
    fi
    
    local repo=$(echo "$model_info" | grep '"repo":' | head -1 | cut -d'"' -f4)
    local template=$(echo "$model_info" | grep '"filename_template":' | head -1 | cut -d'"' -f4)
    local name=$(echo "$model_info" | grep '"name":' | head -1 | cut -d'"' -f4)
    
    # Check if model has default_quant specified
    local model_default_quant=$(echo "$model_info" | grep '"default_quant":' | head -1 | cut -d'"' -f4)
    if [ -z "$quant" ]; then
        if [ -n "$model_default_quant" ]; then
            quant="$model_default_quant"
        else
            quant="$DEFAULT_QUANT"
        fi
    fi
    
    local filename=$(build_filename "$template" "$quant")
    local url=$(build_hf_url "$repo" "$filename")
    local output_path="${MODELS_DIR}/${filename}"
    
    echo -e "${CYAN}Downloading: ${name}${NC}"
    echo "  Quantization: $quant"
    echo "  URL: $url"
    echo "  Destination: $output_path"
    echo ""
    
    # Check if already exists
    if [ -f "$output_path" ]; then
        echo -e "${YELLOW}Model already exists. Skipping download.${NC}"
        return 0
    fi
    
    # Download with curl
    # Using -C - for resume support, -# for progress bar
    if ! curl -C - -# -L "$url" -o "$output_path"; then
        echo -e "${RED}Error: Download failed${NC}"
        # Clean up partial download
        rm -f "$output_path"
        return 1
    fi
    
    # Verify download (basic size check)
    local size=$(stat -c%s "$output_path" 2>/dev/null || stat -f%z "$output_path" 2>/dev/null)
    if [ "$size" -lt 1000000 ]; then
        echo -e "${RED}Error: Downloaded file is too small (${size} bytes). Download may have failed.${NC}"
        rm -f "$output_path"
        return 1
    fi
    
    echo -e "${GREEN}Download complete: ${filename}${NC}"
    return 0
}

# Download custom model from HF path
download_custom() {
    local hf_path="$1"
    # Parse username/repo-name/filename.gguf
    local parts=$(echo "$hf_path" | tr '/' ' ')
    local repo=$(echo "$parts" | awk '{print $1"/"$2}')
    local filename=$(echo "$parts" | awk '{for(i=3;i<=NF;i++) printf "%s", $i; if(i<=NF) printf "/"}')
    
    if [ -z "$repo" ] || [ -z "$filename" ]; then
        echo -e "${RED}Error: Invalid HuggingFace path${NC}"
        echo "Format: username/repo-name/filename.gguf"
        return 1
    fi
    
    local url=$(build_hf_url "$repo" "$filename")
    local output_path="${MODELS_DIR}/${filename}"
    
    echo -e "${CYAN}Downloading custom model${NC}"
    echo "  URL: $url"
    echo ""
    
    if [ -f "$output_path" ]; then
        echo -e "${YELLOW}Model already exists.${NC}"
        return 0
    fi
    
    if ! curl -C - -# -L "$url" -o "$output_path"; then
        echo -e "${RED}Error: Download failed${NC}"
        rm -f "$output_path"
        return 1
    fi
    
    echo -e "${GREEN}Download complete: ${filename}${NC}"
}

# List available models (filtered by hardware)
list_models() {
    local show_all="$1"
    local hw=$(detect_hardware)
    local vram=$(echo "$hw" | grep -o '"vram_gb": [0-9.]*' | cut -d' ' -f2)
    local total_mem=$(echo "$hw" | grep -o '"total_memory_gb": [0-9.]*' | cut -d' ' -f2)
    
    echo -e "${CYAN}Available Models:${NC}"
    echo ""
    
    local models=$(load_models)
    
    # Parse and display each model
    echo "$models" | grep -E '"id"|"name"|"min_vram_gb"|"description"|"tags"' | while read -r line; do
        if echo "$line" | grep -q '"id":'; then
            id=$(echo "$line" | cut -d'"' -f4)
        elif echo "$line" | grep -q '"name":'; then
            name=$(echo "$line" | cut -d'"' -f4)
        elif echo "$line" | grep -q '"min_vram_gb":'; then
            min_vram=$(echo "$line" | grep -o '"min_vram_gb": [0-9.]*' | grep -o '[0-9.]*' | head -1)
            
            # Check if model is suitable - convert to integers for comparison
            suitable=""
            if [ "$show_all" != "all" ]; then
                # Use bc for floating point comparison
                if command -v bc >/dev/null 2>&1; then
                    if (( $(echo "$vram >= $min_vram" | bc -l) )); then
                        suitable="${GREEN}[Compatible]${NC}"
                    else
                        suitable="${YELLOW}[CPU Only]${NC}"
                    fi
                else
                    # Fallback: compare integer parts
                    local vram_int=$(echo "$vram" | cut -d. -f1)
                    local min_vram_int=$(echo "$min_vram" | cut -d. -f1)
                    if [ "$vram_int" -ge "$min_vram_int" ]; then
                        suitable="${GREEN}[Compatible]${NC}"
                    else
                        suitable="${YELLOW}[CPU Only]${NC}"
                    fi
                fi
            fi
            
            # Check if installed
            local template=$(echo "$models" | grep -A 10 "\"id\": \"${id}\"" | grep '"filename_template":' | cut -d'"' -f4)
            local filename=$(build_filename "$template" "$DEFAULT_QUANT")
            local installed=""
            if is_model_installed "$filename"; then
                installed=" ${GREEN}[Installed]${NC}"
            fi
            
            echo -e "${BLUE}${id}${NC}: ${name} ${suitable}${installed}"
            echo "    Min VRAM: ${min_vram} GB"
        elif echo "$line" | grep -q '"description":'; then
            desc=$(echo "$line" | cut -d'"' -f4)
            echo "    ${desc}"
            echo ""
        fi
    done
}

# List installed models only
list_installed_models() {
    echo -e "${CYAN}Installed Models:${NC}"
    echo ""
    
    local found=0
    for file in "$MODELS_DIR"/*.gguf; do
        if [ -f "$file" ]; then
            found=1
            local basename=$(basename "$file")
            local size=$(du -h "$file" 2>/dev/null | cut -f1)
            echo -e "${GREEN}✓${NC} ${basename} (${size})"
        fi
    done
    
    if [ "$found" -eq 0 ]; then
        echo "No models installed yet."
        echo "Run 'oi' to download and install models."
    fi
}

# Get compatible models for interactive selection
get_compatible_models() {
    local hw=$(detect_hardware)
    local vram=$(echo "$hw" | grep -o '"vram_gb": [0-9.]*' | cut -d' ' -f2)
    local total_mem=$(echo "$hw" | grep -o '"total_memory_gb": [0-9.]*' | cut -d' ' -f2)
    
    local models=$(load_models)
    local compatible=""
    
    # Build list of compatible models
    local ids=$(echo "$models" | grep '"id":' | cut -d'"' -f4)
    for id in $ids; do
        local model_info=$(echo "$models" | grep -A 10 "\"id\": \"${id}\"" | head -10)
        local min_vram=$(echo "$model_info" | grep '"min_vram_gb":' | grep -o '[0-9.]*' | head -1)
        local name=$(echo "$model_info" | grep '"name":' | head -1 | cut -d'"' -f4)
        
        if [ -n "$min_vram" ]; then
            local status=""
            # Use bc for floating point comparison if available
            if command -v bc >/dev/null 2>&1; then
                if (( $(echo "$vram >= $min_vram" | bc -l) )); then
                    status="gpu"
                elif (( $(echo "$total_mem >= $min_vram" | bc -l) )); then
                    status="cpu"
                fi
            else
                # Fallback: compare integer parts
                local vram_int=$(echo "$vram" | cut -d. -f1)
                local total_mem_int=$(echo "$total_mem" | cut -d. -f1)
                local min_vram_int=$(echo "$min_vram" | cut -d. -f1)
                if [ "$vram_int" -ge "$min_vram_int" ]; then
                    status="gpu"
                elif [ "$total_mem_int" -ge "$min_vram_int" ]; then
                    status="cpu"
                fi
            fi
            
            if [ -n "$status" ]; then
                compatible="${compatible}${id}|${name}|${status}
"
            fi
        fi
    done
    
    echo -e "$compatible"
}

# Check if a model is installed
is_model_in_array() {
    local target="$1"
    shift
    local arr=("$@")
    for item in "${arr[@]}"; do
        if [ "$item" = "$target" ]; then
            return 0
        fi
    done
    return 1
}

# Interactive model selection
interactive_select() {
    # Output all UI to stderr so only the model ID goes to stdout
    echo "" >&2
    echo -e "${CYAN}╔════════════════════════════════════════════════════════════╗${NC}" >&2
    echo -e "${CYAN}║${NC}     ${CYAN}oi${NC} - One-Command LLM Chat Interface              ${CYAN}║${NC}" >&2
    echo -e "${CYAN}╚════════════════════════════════════════════════════════════╝${NC}" >&2
    echo "" >&2
    
    show_hardware >&2
    echo "" >&2
    
    # Get all models and check which are installed
    local models=$(load_models)
    local ids=$(echo "$models" | grep '"id":' | cut -d'"' -f4)
    local installed=()
    
    for id in $ids; do
        local model_info=$(echo "$models" | grep -A 10 "\"id\": \"${id}\"" | head -10)
        local template=$(echo "$model_info" | grep '"filename_template":' | head -1 | cut -d'"' -f4)
        local filename=$(build_filename "$template" "$DEFAULT_QUANT")
        if is_model_installed "$filename"; then
            installed+=("$id")
        fi
    done
    
    # Build single list of all compatible models
    local compatible=$(get_compatible_models)
    local all_ids=()
    local all_names=()
    local all_status=()
    
    while IFS='|' read -r id name status; do
        [ -z "$id" ] && continue
        all_ids+=("$id")
        all_names+=("$name")
        all_status+=("$status")
    done <<< "$compatible"
    
    # Show single unified menu
    echo -e "${BLUE}Available Models:${NC}" >&2
    echo -e "${BLUE}──────────────────────────────────────────────────────────${NC}" >&2
    
    local i=1
    for idx in "${!all_ids[@]}"; do
        local id="${all_ids[$idx]}"
        local name="${all_names[$idx]}"
        local status="${all_status[$idx]}"
        
        local status_str=""
        if [ "$status" = "gpu" ]; then
            status_str="${GREEN}●${NC} GPU"
        else
            status_str="${YELLOW}●${NC} CPU"
        fi
        
        # Check if installed
        local installed_marker=""
        if is_model_in_array "$id" "${installed[@]}"; then
            installed_marker=" ${GREEN}✓ Installed${NC}"
        fi
        
        printf >&2 "  %-2s %-35s %s%s\n" "$i)" "$name" "$status_str" "$installed_marker"
        ((i++))
    done
    
    echo -e "${BLUE}──────────────────────────────────────────────────────────${NC}" >&2
    echo "" >&2
    echo -e "  ${CYAN}L${NC}) List all available models" >&2
    echo -e "  ${CYAN}H${NC}) Show hardware info" >&2
    echo -e "  ${CYAN}Q${NC}) Quit" >&2
    echo "" >&2
    
    # Read selection
    echo -e "${CYAN}┌──────────────────────────────────────────────────────────┐${NC}" >&2
    read -p "│ Enter choice (1-${#all_ids[@]}, L, H, Q): " choice
    # Clear the input line and draw bottom border on same line
    echo -e "\r${CYAN}└──────────────────────────────────────────────────────────┘${NC}" >&2
    
    case "$choice" in
        [Ll])
            list_models
            return 1
            ;;
        [Hh])
            show_hardware
            return 1
            ;;
        [Qq])
            exit 0
            ;;
        *)
            if [[ "$choice" =~ ^[0-9]+$ ]]; then
                local idx=$((choice - 1))
                
                # Simple index lookup in unified list
                if [ $idx -ge 0 ] && [ $idx -lt ${#all_ids[@]} ]; then
                    local selected_id="${all_ids[$idx]}"
                    # This goes to stdout - the only thing captured by command substitution
                    echo "$selected_id"
                    return 0
                else
                    echo -e "${RED}Invalid selection${NC}" >&2
                    return 1
                fi
            else
                # Try direct ID
                if get_model_info "$choice" > /dev/null; then
                    echo "$choice"
                    return 0
                else
                    echo -e "${RED}Unknown model ID: $choice${NC}" >&2
                    return 1
                fi
            fi
            ;;
    esac
}

# Launch chat with selected model
launch_chat() {
    local model_id="$1"
    local quant="$2"
    local context="${3:-$DEFAULT_CONTEXT}"
    local threads="${4:-$(nproc)}"
    
    local model_info=$(get_model_info "$model_id")
    if [ -z "$model_info" ]; then
        echo -e "${RED}Error: Unknown model ID: ${model_id}${NC}"
        return 1
    fi
    
    # Check for model-specific default_quant
    local model_default_quant=$(echo "$model_info" | grep '"default_quant":' | head -1 | cut -d'"' -f4)
    if [ -z "$quant" ]; then
        if [ -n "$model_default_quant" ]; then
            quant="$model_default_quant"
        else
            quant="$DEFAULT_QUANT"
        fi
    fi
    
    local template=$(echo "$model_info" | grep '"filename_template":' | head -1 | cut -d'"' -f4)
    local filename=$(build_filename "$template" "$quant")
    local model_path="${MODELS_DIR}/${filename}"
    local name=$(echo "$model_info" | grep '"name":' | head -1 | cut -d'"' -f4)
    
    # Check if model exists, download if not
    if [ ! -f "$model_path" ]; then
        echo -e "${YELLOW}Model not found locally. Downloading...${NC}"
        if ! download_model "$model_id" "$quant"; then
            return 1
        fi
    fi
    
    # Verify file exists after potential download
    if [ ! -f "$model_path" ]; then
        echo -e "${RED}Error: Model file not found: $model_path${NC}"
        return 1
    fi
    
    echo -e "${GREEN}Starting chat with: ${name}${NC}"
    echo "  Model: $filename"
    echo "  Context: $context"
    echo "  Threads: $threads"
    echo ""
    echo -e "${CYAN}Type your message and press Enter. Use Ctrl+C to exit.${NC}"
    echo "────────────────────────────────────────"
    
    # Launch llama-cli in interactive mode
    "$LLAMA_CLI" \
        -m "$model_path" \
        -c "$context" \
        -t "$threads" \
        -n -1
}

# Main function
main() {
    # Parse arguments
    local model_id=""
    local quant="$DEFAULT_QUANT"
    local context="$DEFAULT_CONTEXT"
    local threads="$(nproc)"
    local list_mode=""
    local download_path=""
    
    while [[ $# -gt 0 ]]; do
        case "$1" in
            -m|--model)
                model_id="$2"
                shift 2
                ;;
            -q|--quant)
                quant="$2"
                shift 2
                ;;
            -c|--context)
                context="$2"
                shift 2
                ;;
            -t|--threads)
                threads="$2"
                shift 2
                ;;
            -l|--list)
                list_mode="all"
                shift
                ;;
            -i|--installed)
                list_mode="installed"
                shift
                ;;
            -d|--download)
                download_path="$2"
                shift 2
                ;;
            -h|--hardware)
                check_llama_cpp
                show_hardware
                exit 0
                ;;
            --help)
                show_help
                exit 0
                ;;
            *)
                echo -e "${RED}Unknown option: $1${NC}"
                show_help
                exit 1
                ;;
        esac
    done
    
    # Check llama.cpp setup
    check_llama_cpp
    
    # Handle list modes
    if [ "$list_mode" = "all" ]; then
        list_models
        exit 0
    elif [ "$list_mode" = "installed" ]; then
        list_installed_models
        exit 0
    fi
    
    # Handle custom download
    if [ -n "$download_path" ]; then
        download_custom "$download_path"
        exit $?
    fi
    
    # Main flow
    if [ -n "$model_id" ]; then
        # Direct model selection
        launch_chat "$model_id" "$quant" "$context" "$threads"
    else
        # Interactive mode
        while true; do
            if selected=$(interactive_select); then
                launch_chat "$selected" "$quant" "$context" "$threads"
                break
            fi
            # If interactive_select returns 1, it showed info and wants to loop
            echo ""
            read -p "Press Enter to continue..."
            clear
        done
    fi
}

# Run main
main "$@"
